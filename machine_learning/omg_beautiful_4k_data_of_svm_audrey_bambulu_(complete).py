# -*- coding: utf-8 -*-
"""omg - beautiful 4K data of SVM - Audrey Bambulu (complete)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wpHCoCFSciXWaODt6ZT1mfokO2X_UQzJ
"""

from google.colab import drive
drive.mount('/content/drive')

# ======================================================================
# COMPLETE EVALUATION SCRIPT (SVM + KNN + Perceptron + MLP)
# - Per-class balanced accuracy
# - K-Fold = 5 everywhere
# - Neat per-class DataFrames for Tomato and MNIST
# ======================================================================

import os
import cv2
import numpy as np
import pandas as pd
from sklearn.model_selection import KFold, train_test_split
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, matthews_corrcoef
from tensorflow.keras.datasets import mnist
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import Perceptron
from sklearn.neural_network import MLPClassifier
import warnings

# ---------------------------
# GLOBAL SETTINGS
# ---------------------------
K_FOLD = 5
RANDOM_STATE = 42
IMG_SIZE = 128

# ===========================
# 1) LOAD TOMATO DATASET
# ===========================
base_path = "/content/drive/MyDrive/Tomato_Leaf"

class_folders = {
    "Tomato_Bacterial_spot": 0,
    "Tomato_healthy": 1,
    "Tomato_Leaf_Mold": 2,
    "Tomato_Tomato_Yellow_Leaf_Curl_Virus": 3
}

print("Loading images from:", base_path)
X = []
y = []
class_names_tomato = [k for k in class_folders.keys()]

for class_name, class_label in class_folders.items():
    folder_path = os.path.join(base_path, class_name)
    if not os.path.isdir(folder_path):
        print("Warning: folder not found:", folder_path)
        continue

    for img_name in os.listdir(folder_path):
        img_path = os.path.join(folder_path, img_name)
        img = cv2.imread(img_path)
        if img is None:
            continue
        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        X.append(img.flatten())
        y.append(class_label)

X = np.array(X)
y = np.array(y)

print("Tomato dataset loaded:", X.shape[0], "images. Feature shape:", X.shape)

# ---------------------------
# 2) SCALE TOMATO FEATURES
# ---------------------------
scaler = StandardScaler()
if X.shape[0] > 0:
    X = scaler.fit_transform(X)

# ---------------------------
# Utility: per-class metrics
# ---------------------------
def per_class_metrics(y_true, y_pred, labels, label_names=None):
    """
    Compute per-class sensitivity, specificity, balanced_accuracy (A2), per-class MCC, support.
    labels: list/array of label indices (0..n-1); if None, deduced from y_true
    """
    if label_names is None:
        label_names = [str(l) for l in labels]
    cm = confusion_matrix(y_true, y_pred, labels=labels)
    supports = cm.sum(axis=1)
    results = []
    total = cm.sum()
    for i, label in enumerate(labels):
        tp = cm[i, i]
        fn = cm[i, :].sum() - tp
        fp = cm[:, i].sum() - tp
        tn = total - (tp + fn + fp)
        sens = tp / (tp + fn + 1e-8)
        spec = tn / (tn + fp + 1e-8)
        bal_acc = (sens + spec) / 2.0    # A2: balanced per-class accuracy
        # per-class MCC using one-vs-rest binary arrays
        y_true_bin = (y_true == label).astype(int)
        y_pred_bin = (y_pred == label).astype(int)
        try:
            mcc = matthews_corrcoef(y_true_bin, y_pred_bin)
        except Exception:
            mcc = np.nan
        results.append({
            "Class": label_names[i],
            "Support": int(supports[i]),
            "Sensitivity": float(sens),
            "Specificity": float(spec),
            "Balanced_Accuracy": float(bal_acc),
            "MCC": float(mcc)
        })
    df = pd.DataFrame(results)
    return df

# ---------------------------
# Reusable K-Fold evaluator for any sklearn estimator
# ---------------------------
def evaluate_kfold_model_estimator(estimator, X_data, y_data, k=K_FOLD):
    """
    Returns:
      - overall mean accuracy, std, mean sensitivity, mean specificity, mean mcc (across folds)
      - last-fold confusion matrix and last-fold y_true, y_pred (for final per-class extraction)
    """
    kf = KFold(n_splits=k, shuffle=True, random_state=RANDOM_STATE)
    accuracies = []
    sens_list = []
    spec_list = []
    mcc_list = []
    last_cm = None
    last_y_true = None
    last_y_pred = None

    for train_idx, test_idx in kf.split(X_data):
        X_tr, X_te = X_data[train_idx], X_data[test_idx]
        y_tr, y_te = y_data[train_idx], y_data[test_idx]
        # clone estimator with same params
        model = type(estimator)(**estimator.get_params())
        model.fit(X_tr, y_tr)
        y_pred = model.predict(X_te)

        cm = confusion_matrix(y_te, y_pred)
        tp = np.diag(cm)
        fn = cm.sum(axis=1) - tp
        fp = cm.sum(axis=0) - tp
        tn = cm.sum() - (tp + fn + fp)

        sens = np.mean(tp / (tp + fn + 1e-8))
        spec = np.mean(tn / (tn + fp + 1e-8))
        mcc = matthews_corrcoef(y_te, y_pred)

        accuracies.append(accuracy_score(y_te, y_pred))
        sens_list.append(sens)
        spec_list.append(spec)
        mcc_list.append(mcc)

        last_cm = cm
        last_y_true = y_te
        last_y_pred = y_pred

    return {
        "acc_mean": np.mean(accuracies),
        "acc_std": np.std(accuracies),
        "sens_mean": np.mean(sens_list),
        "spec_mean": np.mean(spec_list),
        "mcc_mean": np.mean(mcc_list),
        "last_cm": last_cm,
        "last_y_true": last_y_true,
        "last_y_pred": last_y_pred
    }

# =========================================================================
# SVM: KERNEL / C / GAMMA sweeps (using K_FOLD)
# =========================================================================
print("\n=== SVM K-FOLD (kernels) ===")
kernels = ['linear', 'poly', 'rbf', 'sigmoid']
svm_kfold_results = []
for kernel in kernels:
    svm = SVC(kernel=kernel, C=1.0, gamma='scale', random_state=RANDOM_STATE)
    res = evaluate_kfold_model_estimator(svm, X, y, k=K_FOLD)
    svm_kfold_results.append([kernel, res["acc_mean"], res["acc_std"], res["sens_mean"], res["spec_mean"], res["mcc_mean"]])
    print(f"SVM kernel={kernel} | Acc={res['acc_mean']:.4f} | Sens={res['sens_mean']:.4f} | Spec={res['spec_mean']:.4f} | MCC={res['mcc_mean']:.4f}")

df_svm_kernels = pd.DataFrame(svm_kfold_results, columns=['Kernel','Acc Mean','Acc Std','Sens Mean','Spec Mean','MCC Mean'])
print("\nSVM Kernel K-Fold Summary:")
print(df_svm_kernels)

# C parameter sweep (rbf)
print("\n=== SVM (RBF) : Testing C parameter ===")
C_values = [0.1, 0.5, 1, 5, 10]
results_C = []
for C_val in C_values:
    svm = SVC(kernel='rbf', C=C_val, gamma='scale', random_state=RANDOM_STATE)
    res = evaluate_kfold_model_estimator(svm, X, y, k=K_FOLD)
    results_C.append([C_val, res["acc_mean"], res["acc_std"], res["sens_mean"], res["spec_mean"], res["mcc_mean"]])
    print(f"C={C_val} | Acc={res['acc_mean']:.4f} | Sens={res['sens_mean']:.4f} | Spec={res['spec_mean']:.4f} | MCC={res['mcc_mean']:.4f}")

df_svm_C = pd.DataFrame(results_C, columns=['C','Acc Mean','Acc Std','Sens Mean','Spec Mean','MCC Mean'])
print(df_svm_C)

# Gamma parameter sweep (rbf)
print("\n=== SVM (RBF) : Testing gamma parameter ===")
gamma_values = ['scale', 0.1, 0.5, 1, 2]
results_gamma = []
for g in gamma_values:
    svm = SVC(kernel='rbf', C=1.0, gamma=g, random_state=RANDOM_STATE)
    res = evaluate_kfold_model_estimator(svm, X, y, k=K_FOLD)
    results_gamma.append([g, res["acc_mean"], res["acc_std"], res["sens_mean"], res["spec_mean"], res["mcc_mean"]])
    print(f"gamma={g} | Acc={res['acc_mean']:.4f} | Sens={res['sens_mean']:.4f} | Spec={res['spec_mean']:.4f} | MCC={res['mcc_mean']:.4f}")

df_svm_gamma = pd.DataFrame(results_gamma, columns=['Gamma','Acc Mean','Acc Std','Sens Mean','Spec Mean','MCC Mean'])
print(df_svm_gamma)

# Final SVM train/test (using chosen hyperparams: rbf, C=1, gamma='scale')
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=RANDOM_STATE)
svm_final = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=RANDOM_STATE)
svm_final.fit(X_train, y_train)
y_pred_svm = svm_final.predict(X_test)

print("\n=== FINAL SVM TEST ===")
print("Accuracy:", accuracy_score(y_test, y_pred_svm))
print("Confusion matrix:\n", confusion_matrix(y_test, y_pred_svm))
print(classification_report(y_test, y_pred_svm))

# Per-class table for SVM on Tomato
labels_tomato = np.unique(y)
df_svm_tomato_perclass = per_class_metrics(y_test, y_pred_svm, labels=labels_tomato, label_names=class_names_tomato)
print("\nSVM (Tomato) - Per-class metrics:")
print(df_svm_tomato_perclass)

# =========================================================================
# LOAD MNIST (for comparison)
# =========================================================================
print("\n\nLoading MNIST dataset...")
(X_train_m, y_train_m), (X_test_m, y_test_m) = mnist.load_data()
X_mnist = np.concatenate((X_train_m, X_test_m), axis=0)
y_mnist = np.concatenate((y_train_m, y_test_m), axis=0)
X_mnist = X_mnist.reshape(X_mnist.shape[0], -1)  # flatten
scaler_m = StandardScaler()
X_mnist = scaler_m.fit_transform(X_mnist)
print("MNIST loaded:", X_mnist.shape)

# MNIST SVM K-Fold (kernels)
print("\n=== MNIST: SVM K-FOLD (kernels) ===")
svm_kfold_results_mnist = []
for kernel in kernels:
    svm = SVC(kernel=kernel, C=1.0, gamma='scale', random_state=RANDOM_STATE)
    res = evaluate_kfold_model_estimator(svm, X_mnist, y_mnist, k=K_FOLD)
    svm_kfold_results_mnist.append([kernel, res["acc_mean"], res["acc_std"], res["sens_mean"], res["spec_mean"], res["mcc_mean"]])
    print(f"[MNIST] SVM kernel={kernel} | Acc={res['acc_mean']:.4f} | Sens={res['sens_mean']:.4f} | Spec={res['spec_mean']:.4f} | MCC={res['mcc_mean']:.4f}")

df_svm_kernels_mnist = pd.DataFrame(svm_kfold_results_mnist, columns=['Kernel','Acc Mean','Acc Std','Sens Mean','Spec Mean','MCC Mean'])
print(df_svm_kernels_mnist)

# Final SVM on MNIST (train/test)
X_train_m2, X_test_m2, y_train_m2, y_test_m2 = train_test_split(X_mnist, y_mnist, test_size=0.25, random_state=RANDOM_STATE)
svm_m_final = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=RANDOM_STATE)
svm_m_final.fit(X_train_m2, y_train_m2)
y_pred_svm_m = svm_m_final.predict(X_test_m2)

print("\n=== FINAL MNIST SVM TEST ===")
print("Accuracy:", accuracy_score(y_test_m2, y_pred_svm_m))
print(classification_report(y_test_m2, y_pred_svm_m))

# Per-class SVM metrics on MNIST (digits 0-9)
labels_mnist = np.unique(y_mnist)
digit_names = [str(d) for d in labels_mnist]
df_svm_mnist_perclass = per_class_metrics(y_test_m2, y_pred_svm_m, labels=labels_mnist, label_names=digit_names)
print("\nSVM (MNIST) - Per-class metrics (digits 0-9):")
print(df_svm_mnist_perclass)

# =========================================================================
# KNN, Perceptron, MLP — Tomato evaluations (K-Fold + final train/test + per-class)
# =========================================================================
print("\n\n=== KNN / Perceptron / MLP: TOMATO ===")

# KNN: K-Fold + final
knn = KNeighborsClassifier(n_neighbors=5)
knn_res = evaluate_kfold_model_estimator(knn, X, y, k=K_FOLD)
print(f"KNN K-Fold | Acc={knn_res['acc_mean']:.4f} | Sens={knn_res['sens_mean']:.4f} | Spec={knn_res['spec_mean']:.4f} | MCC={knn_res['mcc_mean']:.4f}")

knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)
print("\nKNN Final test accuracy:", accuracy_score(y_test, y_pred_knn))
print(classification_report(y_test, y_pred_knn))
df_knn_tomato_perclass = per_class_metrics(y_test, y_pred_knn, labels=labels_tomato, label_names=class_names_tomato)
print("\nKNN (Tomato) - Per-class metrics:")
print(df_knn_tomato_perclass)

# Perceptron
perc = Perceptron(max_iter=1000, tol=1e-3, random_state=RANDOM_STATE)
perc_res = evaluate_kfold_model_estimator(perc, X, y, k=K_FOLD)
print(f"\nPerceptron K-Fold | Acc={perc_res['acc_mean']:.4f} | Sens={perc_res['sens_mean']:.4f} | Spec={perc_res['spec_mean']:.4f} | MCC={perc_res['mcc_mean']:.4f}")

perc.fit(X_train, y_train)
y_pred_perc = perc.predict(X_test)
print("\nPerceptron Final test accuracy:", accuracy_score(y_test, y_pred_perc))
print(classification_report(y_test, y_pred_perc))
df_perc_tomato_perclass = per_class_metrics(y_test, y_pred_perc, labels=labels_tomato, label_names=class_names_tomato)
print("\nPerceptron (Tomato) - Per-class metrics:")
print(df_perc_tomato_perclass)

# MLP
mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=RANDOM_STATE)
mlp_res = evaluate_kfold_model_estimator(mlp, X, y, k=K_FOLD)
print(f"\nMLP K-Fold | Acc={mlp_res['acc_mean']:.4f} | Sens={mlp_res['sens_mean']:.4f} | Spec={mlp_res['spec_mean']:.4f} | MCC={mlp_res['mcc_mean']:.4f}")

mlp.fit(X_train, y_train)
y_pred_mlp = mlp.predict(X_test)
print("\nMLP Final test accuracy:", accuracy_score(y_test, y_pred_mlp))
print(classification_report(y_test, y_pred_mlp))
df_mlp_tomato_perclass = per_class_metrics(y_test, y_pred_mlp, labels=labels_tomato, label_names=class_names_tomato)
print("\nMLP (Tomato) - Per-class metrics:")
print(df_mlp_tomato_perclass)

# =========================================================================
# KNN, Perceptron, MLP — MNIST evaluations (K-Fold + final train/test + per-class)
# =========================================================================
print("\n\n=== KNN / Perceptron / MLP: MNIST ===")

# KNN on MNIST
knn_m = KNeighborsClassifier(n_neighbors=5)
knn_m_res = evaluate_kfold_model_estimator(knn_m, X_mnist, y_mnist, k=K_FOLD)
print(f"[MNIST] KNN K-Fold | Acc={knn_m_res['acc_mean']:.4f} | Sens={knn_m_res['sens_mean']:.4f} | Spec={knn_m_res['spec_mean']:.4f} | MCC={knn_m_res['mcc_mean']:.4f}")

knn_m.fit(X_train_m2, y_train_m2)
y_pred_knn_m = knn_m.predict(X_test_m2)
print("[MNIST] KNN final accuracy:", accuracy_score(y_test_m2, y_pred_knn_m))
df_knn_mnist_perclass = per_class_metrics(y_test_m2, y_pred_knn_m, labels=labels_mnist, label_names=digit_names)
print("\nKNN (MNIST) - Per-class metrics:")
print(df_knn_mnist_perclass)

# Perceptron on MNIST
perc_m = Perceptron(max_iter=1000, tol=1e-3, random_state=RANDOM_STATE)
perc_m_res = evaluate_kfold_model_estimator(perc_m, X_mnist, y_mnist, k=K_FOLD)
print(f"[MNIST] Perceptron K-Fold | Acc={perc_m_res['acc_mean']:.4f} | Sens={perc_m_res['sens_mean']:.4f} | Spec={perc_m_res['spec_mean']:.4f} | MCC={perc_m_res['mcc_mean']:.4f}")

perc_m.fit(X_train_m2, y_train_m2)
y_pred_perc_m = perc_m.predict(X_test_m2)
print("[MNIST] Perceptron final accuracy:", accuracy_score(y_test_m2, y_pred_perc_m))
df_perc_mnist_perclass = per_class_metrics(y_test_m2, y_pred_perc_m, labels=labels_mnist, label_names=digit_names)
print("\nPerceptron (MNIST) - Per-class metrics:")
print(df_perc_mnist_perclass)

# MLP on MNIST
mlp_m = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=RANDOM_STATE)
mlp_m_res = evaluate_kfold_model_estimator(mlp_m, X_mnist, y_mnist, k=K_FOLD)
print(f"[MNIST] MLP K-Fold | Acc={mlp_m_res['acc_mean']:.4f} | Sens={mlp_m_res['sens_mean']:.4f} | Spec={mlp_m_res['spec_mean']:.4f} | MCC={mlp_m_res['mcc_mean']:.4f}")

mlp_m.fit(X_train_m2, y_train_m2)
y_pred_mlp_m = mlp_m.predict(X_test_m2)
print("[MNIST] MLP final accuracy:", accuracy_score(y_test_m2, y_pred_mlp_m))
df_mlp_mnist_perclass = per_class_metrics(y_test_m2, y_pred_mlp_m, labels=labels_mnist, label_names=digit_names)
print("\nMLP (MNIST) - Per-class metrics:")
print(df_mlp_mnist_perclass)

# =========================================================================
# COLLECT and COMPARISON TABLES (summary per classifier)
# =========================================================================
print("\n\n=== SUMMARY TABLES: FINAL TEST (Tomato & MNIST) PER-CLASS (Balanced Acc A2) ===")

# For Tomato: create combined table per classifier (stacked)
def add_classifier_perclass_table(df_perclass, classifier_name):
    df = df_perclass.copy()
    df["Classifier"] = classifier_name
    # reorder columns
    return df[["Classifier","Class","Support","Sensitivity","Specificity","Balanced_Accuracy","MCC"]]

tomato_tables = pd.concat([
    add_classifier_perclass_table(df_svm_tomato_perclass, "SVM (RBF)"),
    add_classifier_perclass_table(df_knn_tomato_perclass, "KNN (k=5)"),
    add_classifier_perclass_table(df_perc_tomato_perclass, "Perceptron"),
    add_classifier_perclass_table(df_mlp_tomato_perclass, "MLP (100)")
], ignore_index=True)

print("\n--- Tomato per-class metrics (all classifiers) ---")
print(tomato_tables)

mnist_tables = pd.concat([
    add_classifier_perclass_table(df_svm_mnist_perclass, "SVM (RBF)"),
    add_classifier_perclass_table(df_knn_mnist_perclass, "KNN (k=5)"),
    add_classifier_perclass_table(df_perc_mnist_perclass, "Perceptron"),
    add_classifier_perclass_table(df_mlp_mnist_perclass, "MLP (100)")
], ignore_index=True)

print("\n--- MNIST per-class metrics (all classifiers) ---")
print(mnist_tables)

# Save CSVs for convenience (optional)
out_dir = "evaluation_results"
os.makedirs(out_dir, exist_ok=True)
tomato_tables.to_csv(os.path.join(out_dir, "tomato_per_class_all_classifiers.csv"), index=False)
mnist_tables.to_csv(os.path.join(out_dir, "mnist_per_class_all_classifiers.csv"), index=False)
df_svm_kernels.to_csv(os.path.join(out_dir, "svm_kernels_tomato_kfold.csv"), index=False)
df_svm_kernels_mnist.to_csv(os.path.join(out_dir, "svm_kernels_mnist_kfold.csv"), index=False)
df_svm_C.to_csv(os.path.join(out_dir, "svm_C_results.csv"), index=False)
df_svm_gamma.to_csv(os.path.join(out_dir, "svm_gamma_results.csv"), index=False)

print(f"\nSaved summary CSVs into folder: {out_dir}")
print("=== END ===")